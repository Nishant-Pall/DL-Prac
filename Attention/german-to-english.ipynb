{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit"
  },
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, LSTM, Dense, Embedding, Bidirectional, RepeatVector, Concatenate, Dot, Lambda\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "import keras.backend as K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax_over_time(x):\n",
    "    assert(K.ndim(x) > 0)\n",
    "    e = K.exp(x - K.max(x, axis=1, keepdims=True))\n",
    "    s = K.sum(e, axis=1, keepdims=True)\n",
    "    return e/s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#config\n",
    "\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 30\n",
    "LATENT_DIM = 128\n",
    "LATENT_DIM_DECODER = 128\n",
    "NUM_SAMPLES = 20000\n",
    "MAX_SEQUENCE_LENGTH = 100\n",
    "MAX_NUM_WORDS = 20000\n",
    "EMBEDDING_DIM = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_texts = []\n",
    "target_texts = []\n",
    "target_texts_inputs = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = 0\n",
    "for line in open(\"deu.txt\"):\n",
    "    t+=1\n",
    "    if t > NUM_SAMPLES:\n",
    "        break\n",
    "    if '\\t' not in line:\n",
    "        continue\n",
    "\n",
    "    input_text, translation, *rest = line.rstrip().split('\\t')\n",
    "    target_text = translation + ' <eos>'\n",
    "    target_text_input = '<sos> ' + translation\n",
    "\n",
    "    input_texts.append(input_text)\n",
    "    target_texts.append(target_text)\n",
    "    target_texts_inputs.append(target_text_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "20000"
      ]
     },
     "metadata": {},
     "execution_count": 8
    }
   ],
   "source": [
    "len(input_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_inputs = Tokenizer(num_words=MAX_NUM_WORDS)\n",
    "tokenizer_inputs.fit_on_texts(input_texts)\n",
    "input_sequences = tokenizer_inputs.texts_to_sequences(input_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2idx_inputs = tokenizer_inputs.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "3676"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "len(word2idx_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len_input = max(len(s) for s in input_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ],
   "source": [
    "max_len_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer_outputs = Tokenizer(num_words=MAX_NUM_WORDS, filters='')\n",
    "tokenizer_outputs.fit_on_texts(target_texts + target_texts_inputs)\n",
    "target_sequences = tokenizer_outputs.texts_to_sequences(target_texts)\n",
    "target_sequences_inputs = tokenizer_outputs.texts_to_sequences(target_texts_inputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2idx_outputs = tokenizer_outputs.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "8185"
      ]
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "source": [
    "len(word2idx_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_words_output = len(word2idx_outputs) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len_output = max(len(s) for s in target_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "source": [
    "max_len_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_inputs = pad_sequences(input_sequences, maxlen=max_len_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(20000, 6)"
      ]
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "source": [
    "encoder_inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_inputs = pad_sequences(target_sequences_inputs, padding='post', maxlen=max_len_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_targets = pad_sequences(target_sequences, padding='post',maxlen=max_len_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(20000, 11)"
      ]
     },
     "metadata": {},
     "execution_count": 24
    }
   ],
   "source": [
    "decoder_inputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(20000, 11)"
      ]
     },
     "metadata": {},
     "execution_count": 25
    }
   ],
   "source": [
    "decoder_targets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec = {}\n",
    "with open(os.path.join(f'glove.6B.{EMBEDDING_DIM}d.txt')) as f:\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        vec = np.asarray(values[1:], dtype='float32')\n",
    "        word2vec[word] = vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "400000"
      ]
     },
     "metadata": {},
     "execution_count": 27
    }
   ],
   "source": [
    "len(word2vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "3677"
      ]
     },
     "metadata": {},
     "execution_count": 28
    }
   ],
   "source": [
    "num_words = min(MAX_NUM_WORDS, len(word2idx_inputs) + 1)\n",
    "num_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix = np.zeros((num_words, EMBEDDING_DIM))\n",
    "for word, i in word2idx_inputs.items():\n",
    "    if i < MAX_NUM_WORDS:\n",
    "        embedding_vector = word2vec.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_layer = Embedding(\n",
    "    num_words,\n",
    "    EMBEDDING_DIM,\n",
    "    weights=[embedding_matrix],\n",
    "    input_length=max_len_input\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_targets_one_hot = np.zeros(\n",
    "    (\n",
    "        len(input_texts),\n",
    "        max_len_output,\n",
    "        num_words_output\n",
    "    ),\n",
    "    dtype='float32'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, d in enumerate(decoder_targets):\n",
    "    for t, word in enumerate(d):\n",
    "        if word > 0:\n",
    "            decoder_targets_one_hot[i, t, word] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(20000, 11, 8186)"
      ]
     },
     "metadata": {},
     "execution_count": 33
    }
   ],
   "source": [
    "decoder_targets_one_hot.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MODEL\n",
    "\n",
    "# Encoder\n",
    "encoder_inputs_placeholder = Input(shape=(max_len_input,))\n",
    "x = embedding_layer(encoder_inputs_placeholder)\n",
    "encoder = Bidirectional(LSTM(\n",
    "    LATENT_DIM,\n",
    "    return_sequences=True,\n",
    "    dropout=0.5\n",
    "))\n",
    "encoder_outputs = encoder(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decoder\n",
    "decoder_inputs_placeholder = Input(shape=(max_len_output,))\n",
    "\n",
    "# decoder embedding\n",
    "decoder_embedding = Embedding(num_words_output, EMBEDDING_DIM)\n",
    "decoder_inputs_x = decoder_embedding(decoder_inputs_placeholder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ATTENTION\n",
    "# Attention layers need to be global because they will be repeated Ty times at the decoder\n",
    "attn_repeat_layer = RepeatVector(max_len_input)\n",
    "attn_concat_layer = Concatenate(axis = -1)\n",
    "attn_dense1 = Dense(10, activation='tanh')\n",
    "attn_dense2 = Dense(1, activation=softmax_over_time)\n",
    "attn_dot = Dot(axes=1) # to perform weighted sum of alpha[t] * h[t]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def one_step_attention(h, st_1):\n",
    "    # h = h(1),...., h(Tx), shape = (Tx, LATENT_DIM * 2)\n",
    "    # st_1 = st(t-1), shape = (LATENT_DIM_DECODER,)\n",
    "\n",
    "    # copy s(t-1) Tx times\n",
    "    # now shape = (Tx, LATEN_DIM_DECODER)\n",
    "    st_1 = attn_repeat_layer(st_1)\n",
    "\n",
    "    # Concatenate all h(t)'s with s(t-1)\n",
    "    # Now of shape (Tx, LATENT_DIM_DECODER + LATENT_DIM * 2)\n",
    "    x = attn_concat_layer([h, st_1])\n",
    "\n",
    "    # Neural net first layer\n",
    "    x = attn_dense1(x)\n",
    "\n",
    "    # Neural net second layer with softmax_over_time\n",
    "    alphas = attn_dense2(x)\n",
    "\n",
    "    # \"Dot\" the alphas and the h's\n",
    "    # Remember a.dot(b) = sum over a[t] * b[t]\n",
    "    context = attn_dot([alphas, h])\n",
    "\n",
    "    return context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the rest of the decoder (after attention)\n",
    "decoder_lstm = LSTM(LATENT_DIM_DECODER, return_state=True)\n",
    "decoder_dense = Dense(num_words_output, activation='softmax')\n",
    "\n",
    "initial_s = Input(shape=(LATENT_DIM_DECODER,), name='s0')\n",
    "initial_c = Input(shape=(LATENT_DIM_DECODER), name='c0')\n",
    "context_last_word_concat_layer = Concatenate(axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unlike previous seq2seq, we cannot get the output\n",
    "# all in one step\n",
    "# Instead we need to do Ty steps\n",
    "# And in each of those steps, we need to consider\n",
    "# all Tx h's\n",
    "\n",
    "# s, c will be re-assigned in each iteration of the loop\n",
    "s = initial_s\n",
    "c = initial_c\n",
    "\n",
    "# collect outputs in a list first\n",
    "outputs = []\n",
    "for t in range(max_len_output): # Ty times\n",
    "    # get context using attetnion\n",
    "    context = one_step_attention(encoder_outputs, s)\n",
    "\n",
    "    # we need a different layer for each time step\n",
    "    selector = Lambda(lambda x: x[:, t:t+1])\n",
    "    xt = selector(decoder_inputs_x)\n",
    "\n",
    "    # combine\n",
    "    decoder_lstm_input = context_last_word_concat_layer([context, xt])\n",
    "\n",
    "    # pass the combined [context, last word] into the LSTM\n",
    "    # along with [s, c]\n",
    "    # get the new [s, c] and output\n",
    "    o, s, c = decoder_lstm(decoder_lstm_input, initial_state=[s, c])\n",
    "\n",
    "    # final dense layer to get next word prediction\n",
    "    decoder_outputs = decoder_dense(o)\n",
    "    outputs.append(decoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'outputs' is now a list of length Ty\n",
    "# each element is of shape (batch size, output vocab size)\n",
    "# therefore if we simply stack all the outputs into 1 tensor\n",
    "# it would be of shape T x N x D\n",
    "# we would like it to be of shape N x T x D\n",
    "\n",
    "def stack_and_transpose(x):\n",
    "    # x is a list of length T, each element is a batch_size x output_vocab tensor\n",
    "    x = K.stack(x) # is now T x batch_size x output_vocab_size tensor\n",
    "\n",
    "    # is now batch_size x T x output_vocab_size\n",
    "    x = K.permute_dimensions(x, pattern=(1, 0, 2))\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make it a layer\n",
    "stacker = Lambda(stack_and_transpose)\n",
    "outputs = stacker(outputs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model(\n",
    "    inputs = [\n",
    "        encoder_inputs_placeholder,\n",
    "        decoder_inputs_placeholder,\n",
    "        initial_s,\n",
    "        initial_c\n",
    "    ],\n",
    "    outputs=outputs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_loss(y_true, y_pred):\n",
    "    # both are of shape N x T x K\n",
    "    mask = K.cast(y_true > 0, dtype='float32')\n",
    "    out = mask * y_true * K.log(y_pred)\n",
    "    return -K.sum(out) / K.sum(mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = np.zeros((len(encoder_inputs), LATENT_DIM_DECODER))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/30\n",
      "250/250 [==============================] - 169s 469ms/step - loss: 2.6832 - accuracy: 0.0879 - val_loss: 2.6463 - val_accuracy: 0.0909\n",
      "Epoch 2/30\n",
      "250/250 [==============================] - 86s 341ms/step - loss: 2.1958 - accuracy: 0.0962 - val_loss: 2.5970 - val_accuracy: 0.1141\n",
      "Epoch 3/30\n",
      "250/250 [==============================] - 88s 353ms/step - loss: 2.1284 - accuracy: 0.1120 - val_loss: 2.5154 - val_accuracy: 0.1296\n",
      "Epoch 4/30\n",
      "250/250 [==============================] - 87s 350ms/step - loss: 2.0336 - accuracy: 0.1212 - val_loss: 2.4223 - val_accuracy: 0.1304\n",
      "Epoch 5/30\n",
      "250/250 [==============================] - 85s 342ms/step - loss: 1.9382 - accuracy: 0.1238 - val_loss: 2.2743 - val_accuracy: 0.1384\n",
      "Epoch 6/30\n",
      "250/250 [==============================] - 89s 355ms/step - loss: 1.8110 - accuracy: 0.1385 - val_loss: 2.1740 - val_accuracy: 0.1707\n",
      "Epoch 7/30\n",
      "250/250 [==============================] - 85s 342ms/step - loss: 1.6843 - accuracy: 0.1616 - val_loss: 2.0860 - val_accuracy: 0.1870\n",
      "Epoch 8/30\n",
      "250/250 [==============================] - 86s 342ms/step - loss: 1.5887 - accuracy: 0.1741 - val_loss: 2.0301 - val_accuracy: 0.1934\n",
      "Epoch 9/30\n",
      "250/250 [==============================] - 89s 355ms/step - loss: 1.5126 - accuracy: 0.1835 - val_loss: 1.9832 - val_accuracy: 0.1965\n",
      "Epoch 10/30\n",
      "250/250 [==============================] - 87s 347ms/step - loss: 1.4384 - accuracy: 0.1883 - val_loss: 1.9409 - val_accuracy: 0.2017\n",
      "Epoch 11/30\n",
      "250/250 [==============================] - 88s 351ms/step - loss: 1.3877 - accuracy: 0.1927 - val_loss: 1.8987 - val_accuracy: 0.2065\n",
      "Epoch 12/30\n",
      "250/250 [==============================] - 90s 360ms/step - loss: 1.3248 - accuracy: 0.2006 - val_loss: 1.8761 - val_accuracy: 0.2101\n",
      "Epoch 13/30\n",
      "250/250 [==============================] - 90s 360ms/step - loss: 1.2707 - accuracy: 0.2042 - val_loss: 1.8378 - val_accuracy: 0.2168\n",
      "Epoch 14/30\n",
      "250/250 [==============================] - 93s 371ms/step - loss: 1.2059 - accuracy: 0.2111 - val_loss: 1.8135 - val_accuracy: 0.2198\n",
      "Epoch 15/30\n",
      "250/250 [==============================] - 91s 365ms/step - loss: 1.1683 - accuracy: 0.2142 - val_loss: 1.7834 - val_accuracy: 0.2230\n",
      "Epoch 16/30\n",
      "250/250 [==============================] - 89s 357ms/step - loss: 1.1150 - accuracy: 0.2186 - val_loss: 1.7624 - val_accuracy: 0.2250\n",
      "Epoch 17/30\n",
      "250/250 [==============================] - 89s 356ms/step - loss: 1.0762 - accuracy: 0.2203 - val_loss: 1.7400 - val_accuracy: 0.2267\n",
      "Epoch 18/30\n",
      "250/250 [==============================] - 90s 358ms/step - loss: 1.0424 - accuracy: 0.2228 - val_loss: 1.7282 - val_accuracy: 0.2283\n",
      "Epoch 19/30\n",
      "250/250 [==============================] - 90s 359ms/step - loss: 1.0071 - accuracy: 0.2256 - val_loss: 1.7025 - val_accuracy: 0.2315\n",
      "Epoch 20/30\n",
      "250/250 [==============================] - 89s 355ms/step - loss: 0.9640 - accuracy: 0.2289 - val_loss: 1.6905 - val_accuracy: 0.2322\n",
      "Epoch 21/30\n",
      "250/250 [==============================] - 67s 268ms/step - loss: 0.9386 - accuracy: 0.2307 - val_loss: 1.6789 - val_accuracy: 0.2330\n",
      "Epoch 22/30\n",
      "250/250 [==============================] - 65s 260ms/step - loss: 0.8997 - accuracy: 0.2341 - val_loss: 1.6660 - val_accuracy: 0.2343\n",
      "Epoch 23/30\n",
      "250/250 [==============================] - 65s 260ms/step - loss: 0.8740 - accuracy: 0.2365 - val_loss: 1.6563 - val_accuracy: 0.2349\n",
      "Epoch 24/30\n",
      "250/250 [==============================] - 65s 259ms/step - loss: 0.8405 - accuracy: 0.2382 - val_loss: 1.6457 - val_accuracy: 0.2364\n",
      "Epoch 25/30\n",
      "250/250 [==============================] - 65s 259ms/step - loss: 0.8148 - accuracy: 0.2416 - val_loss: 1.6336 - val_accuracy: 0.2384\n",
      "Epoch 26/30\n",
      "250/250 [==============================] - 65s 260ms/step - loss: 0.7913 - accuracy: 0.2434 - val_loss: 1.6287 - val_accuracy: 0.2387\n",
      "Epoch 27/30\n",
      "250/250 [==============================] - 66s 265ms/step - loss: 0.7655 - accuracy: 0.2453 - val_loss: 1.6195 - val_accuracy: 0.2399\n",
      "Epoch 28/30\n",
      "250/250 [==============================] - 60s 239ms/step - loss: 0.7346 - accuracy: 0.2478 - val_loss: 1.6132 - val_accuracy: 0.2401\n",
      "Epoch 29/30\n",
      "250/250 [==============================] - 64s 256ms/step - loss: 0.7076 - accuracy: 0.2516 - val_loss: 1.6079 - val_accuracy: 0.2407\n",
      "Epoch 30/30\n",
      "250/250 [==============================] - 64s 255ms/step - loss: 0.6911 - accuracy: 0.2543 - val_loss: 1.6005 - val_accuracy: 0.2420\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f514b23e250>"
      ]
     },
     "metadata": {},
     "execution_count": 46
    }
   ],
   "source": [
    "model.fit(\n",
    "    [encoder_inputs, decoder_inputs, z, z], decoder_targets_one_hot,\n",
    "    batch_size=BATCH_SIZE,\n",
    "    epochs=EPOCHS,\n",
    "    validation_split=0.2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "##### Make predictions #####\n",
    "# As with the poetry example, we need to create another model\n",
    "# that can take in the RNN state and previous word as input\n",
    "# and accept a T=1 sequence.\n",
    "\n",
    "# The encoder will be stand-alone\n",
    "# From this we will get our initial decoder hidden state\n",
    "# i.e. h(1), ..., h(Tx)\n",
    "encoder_model = Model(encoder_inputs_placeholder, encoder_outputs)\n",
    "\n",
    "# next we define a T=1 decoder model\n",
    "encoder_outputs_as_input = Input(shape=(max_len_input, LATENT_DIM * 2))\n",
    "decoder_inputs_single = Input(shape=(1,))\n",
    "decoder_inputs_single_x = decoder_embedding(decoder_inputs_single)\n",
    "\n",
    "# no need to loop this time\n",
    "context = one_step_attention(encoder_outputs_as_input, initial_s)\n",
    "\n",
    "decoder_lstm_input = context_last_word_concat_layer([context, decoder_inputs_single_x])\n",
    "\n",
    "o, s, c = decoder_lstm(decoder_lstm_input, initial_state=[initial_s, initial_c])\n",
    "decoder_outputs = decoder_dense(o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_model = Model(\n",
    "    inputs = [\n",
    "        decoder_inputs_single,\n",
    "        encoder_outputs_as_input,\n",
    "        initial_s,\n",
    "        initial_c\n",
    "    ],\n",
    "    outputs = [decoder_outputs, s, c]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx2word_eng = {v:k for k, v in word2idx_inputs.items()}\n",
    "idx2word_trans = {v:k for k, v in word2idx_outputs.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq):\n",
    "    # Encode the input as state vectors\n",
    "    enc_out = encoder_model.predict(input_seq)\n",
    "\n",
    "    # Generate empty target sequence of length 1\n",
    "    target_seq = np.zeros((1,1))\n",
    "\n",
    "    # Populate the first character of target sequence with the start character.\n",
    "    # tokenizer lower-cases all words\n",
    "    target_seq[0, 0] = word2idx_outputs['<sos>']\n",
    "\n",
    "    # if we get this we break\n",
    "    eos = word2idx_outputs['<eos>']\n",
    "\n",
    "    # [s, c] will be updated in each iteration\n",
    "    s = np.zeros((1, LATENT_DIM_DECODER))\n",
    "    c = np.zeros((1, LATENT_DIM_DECODER))\n",
    "\n",
    "    outputs_sentence = []\n",
    "    for _ in range(max_len_output):\n",
    "        o, s, c = decoder_model.predict([target_seq, enc_out, s, c])\n",
    "\n",
    "        # get the word\n",
    "        idx = np.argmax(o.flatten())\n",
    "        \n",
    "        # end sentence of eos\n",
    "        if eos == idx:\n",
    "            break\n",
    "\n",
    "        word = ''\n",
    "        if idx > 0:\n",
    "            word = idx2word_trans[idx]\n",
    "            outputs_sentence.append(word)\n",
    "\n",
    "\n",
    "        target_seq[0,0] = idx\n",
    "\n",
    "    return ' '.join(outputs_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    i = np.random.choice(len(input_texts))\n",
    "    input_seq = encoder_inputs[i:i+1]\n",
    "    translation = decode_sequence(input_seq)\n",
    "    print('-')\n",
    "    print('Input sentence:', input_texts[i])\n",
    "    print('Predicted translation:', translation)\n",
    "    print('Actual translation:', target_texts[i])\n",
    "\n",
    "    ans = input(\"Continue? [Y/n]\")\n",
    "    if ans and ans.lower().startswith('n'):\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}