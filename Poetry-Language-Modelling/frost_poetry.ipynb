{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python385jvsc74a57bd0916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1",
   "display_name": "Python 3.8.5 64-bit"
  },
  "metadata": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "from keras.layers import Input, LSTM, Dense, Embedding\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.preprocessing.text import Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_SEQUENCE_LENGTH = 100\n",
    "MAX_VOCAB_SIZE = 20000\n",
    "EMBEDDING_DIM = 50\n",
    "VALIDATION_SPLIT = 0.2\n",
    "BATCH_SIZE = 128\n",
    "EPOCHS = 500\n",
    "LATENT_DIM = 25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_texts = []\n",
    "target_texts = []\n",
    "\n",
    "for line in open('robert_frost.txt'):\n",
    "    line = line.rstrip()\n",
    "    if not line:\n",
    "        continue\n",
    "\n",
    "    input_line = '<sos> ' + line\n",
    "    target_line = line + ' <eos>'\n",
    "\n",
    "    input_texts.append(input_line)\n",
    "    target_texts.append(target_line)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_lines = input_texts + target_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=MAX_VOCAB_SIZE, filters='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.fit_on_texts(all_lines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_sequences = tokenizer.texts_to_sequences(input_texts)\n",
    "target_sequences = tokenizer.texts_to_sequences(target_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "1436"
      ]
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "len(target_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_sequence_length_from_data = max(len(s) for s in input_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "max_sequence_length_from_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "3056"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "word2idx = tokenizer.word_index\n",
    "len(word2idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_sequence_length = min(MAX_SEQUENCE_LENGTH, max_sequence_length_from_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "max_sequence_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_sequences = pad_sequences(input_sequences, maxlen=max_sequence_length, padding='post')\n",
    "target_sequences = pad_sequences(target_sequences, maxlen=max_sequence_length, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(1436, 12)"
      ]
     },
     "metadata": {},
     "execution_count": 16
    }
   ],
   "source": [
    "input_sequences.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(1436, 12)"
      ]
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "target_sequences.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "word2vec={}\n",
    "\n",
    "with open(os.path.join(\"glove.6B.50d.txt\")) as f:\n",
    "    for line in f:\n",
    "        values = line.split()\n",
    "        word = values[0]\n",
    "        vec = np.asarray(values[1:], dtype='float32')\n",
    "        word2vec[word] = vec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "400000"
      ]
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "source": [
    "len(word2vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_words = min(MAX_VOCAB_SIZE, len(word2idx) + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "3057"
      ]
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "source": [
    "num_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_matrix = np.zeros((num_words, EMBEDDING_DIM))\n",
    "for word, i in word2idx.items():\n",
    "    if i < MAX_VOCAB_SIZE:\n",
    "        embedding_vector = word2vec.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[i] = embedding_vector\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "one_hot_targets = np.zeros(\n",
    "    (len(input_sequences), max_sequence_length, num_words))\n",
    "for i, target_sequence in enumerate(target_sequences):\n",
    "    for t, word in enumerate(target_sequence):\n",
    "        if word > 0:\n",
    "            one_hot_targets[i, t, word] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "len(input_sequences): 1436\nmax_sequence_length: 12\nnum_words: 3057\none_hot_targets.shape: (1436, 12, 3057)\n"
     ]
    }
   ],
   "source": [
    "print(f'len(input_sequences): {len(input_sequences)}')\n",
    "print(f'max_sequence_length: {max_sequence_length}')\n",
    "print(f'num_words: {num_words}')\n",
    "print(f'one_hot_targets.shape: {one_hot_targets.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_layer = Embedding(\n",
    "    num_words,\n",
    "    EMBEDDING_DIM,\n",
    "    weights=[embedding_matrix]\n",
    "    # tranaible = False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "input1 = Input(shape=(max_sequence_length,))\n",
    "initial_h = Input(shape=(LATENT_DIM,))\n",
    "initial_c = Input(shape=(LATENT_DIM))\n",
    "x = embedding_layer(input1)\n",
    "lstm = LSTM(LATENT_DIM, return_sequences=True, return_state=True)\n",
    "x,_,_ = lstm(x, initial_state=[initial_h, initial_c])\n",
    "dense = Dense(num_words, activation='softmax')\n",
    "output = dense(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model([input1, initial_h, initial_c], output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    loss='categorical_crossentropy',\n",
    "    optimizer='adam',\n",
    "    metrics=['accuracy'],\n",
    "    # trainable = False \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = np.zeros((len(input_sequences),LATENT_DIM))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "tags": [
     "outputPrepend"
    ]
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "46 - val_loss: 4.9225 - val_accuracy: 0.1007\n",
      "Epoch 361/500\n",
      "9/9 [==============================] - 1s 110ms/step - loss: 3.1322 - accuracy: 0.1848 - val_loss: 4.9236 - val_accuracy: 0.1007\n",
      "Epoch 362/500\n",
      "9/9 [==============================] - 1s 89ms/step - loss: 3.1265 - accuracy: 0.1814 - val_loss: 4.9250 - val_accuracy: 0.1007\n",
      "Epoch 363/500\n",
      "9/9 [==============================] - 1s 112ms/step - loss: 3.1413 - accuracy: 0.1820 - val_loss: 4.9257 - val_accuracy: 0.0998\n",
      "Epoch 364/500\n",
      "9/9 [==============================] - 1s 89ms/step - loss: 3.1112 - accuracy: 0.1837 - val_loss: 4.9273 - val_accuracy: 0.0998\n",
      "Epoch 365/500\n",
      "9/9 [==============================] - 1s 124ms/step - loss: 3.1068 - accuracy: 0.1802 - val_loss: 4.9286 - val_accuracy: 0.1007\n",
      "Epoch 366/500\n",
      "9/9 [==============================] - 1s 97ms/step - loss: 3.1125 - accuracy: 0.1798 - val_loss: 4.9297 - val_accuracy: 0.1004\n",
      "Epoch 367/500\n",
      "9/9 [==============================] - 1s 105ms/step - loss: 3.1037 - accuracy: 0.1851 - val_loss: 4.9304 - val_accuracy: 0.1010\n",
      "Epoch 368/500\n",
      "9/9 [==============================] - 1s 92ms/step - loss: 3.1040 - accuracy: 0.1861 - val_loss: 4.9325 - val_accuracy: 0.1004\n",
      "Epoch 369/500\n",
      "9/9 [==============================] - 1s 89ms/step - loss: 3.0930 - accuracy: 0.1830 - val_loss: 4.9341 - val_accuracy: 0.0995\n",
      "Epoch 370/500\n",
      "9/9 [==============================] - 1s 102ms/step - loss: 3.0959 - accuracy: 0.1855 - val_loss: 4.9332 - val_accuracy: 0.1001\n",
      "Epoch 371/500\n",
      "9/9 [==============================] - 1s 84ms/step - loss: 3.1002 - accuracy: 0.1890 - val_loss: 4.9358 - val_accuracy: 0.0998\n",
      "Epoch 372/500\n",
      "9/9 [==============================] - 1s 108ms/step - loss: 3.1031 - accuracy: 0.1861 - val_loss: 4.9369 - val_accuracy: 0.0998\n",
      "Epoch 373/500\n",
      "9/9 [==============================] - 1s 89ms/step - loss: 3.0699 - accuracy: 0.1889 - val_loss: 4.9386 - val_accuracy: 0.0992\n",
      "Epoch 374/500\n",
      "9/9 [==============================] - 1s 86ms/step - loss: 3.0676 - accuracy: 0.1870 - val_loss: 4.9394 - val_accuracy: 0.1001\n",
      "Epoch 375/500\n",
      "9/9 [==============================] - 1s 95ms/step - loss: 3.0971 - accuracy: 0.1885 - val_loss: 4.9411 - val_accuracy: 0.0992\n",
      "Epoch 376/500\n",
      "9/9 [==============================] - 1s 109ms/step - loss: 3.0764 - accuracy: 0.1869 - val_loss: 4.9426 - val_accuracy: 0.0998\n",
      "Epoch 377/500\n",
      "9/9 [==============================] - 1s 95ms/step - loss: 3.0600 - accuracy: 0.1894 - val_loss: 4.9445 - val_accuracy: 0.0992\n",
      "Epoch 378/500\n",
      "9/9 [==============================] - 1s 122ms/step - loss: 3.0999 - accuracy: 0.1876 - val_loss: 4.9455 - val_accuracy: 0.1004\n",
      "Epoch 379/500\n",
      "9/9 [==============================] - 1s 86ms/step - loss: 3.1041 - accuracy: 0.1908 - val_loss: 4.9470 - val_accuracy: 0.1007\n",
      "Epoch 380/500\n",
      "9/9 [==============================] - 1s 112ms/step - loss: 3.0161 - accuracy: 0.1886 - val_loss: 4.9494 - val_accuracy: 0.1010\n",
      "Epoch 381/500\n",
      "9/9 [==============================] - 1s 89ms/step - loss: 3.0586 - accuracy: 0.1882 - val_loss: 4.9500 - val_accuracy: 0.1007\n",
      "Epoch 382/500\n",
      "9/9 [==============================] - 1s 101ms/step - loss: 3.0484 - accuracy: 0.1926 - val_loss: 4.9504 - val_accuracy: 0.1007\n",
      "Epoch 383/500\n",
      "9/9 [==============================] - 1s 95ms/step - loss: 3.0504 - accuracy: 0.1915 - val_loss: 4.9536 - val_accuracy: 0.1004\n",
      "Epoch 384/500\n",
      "9/9 [==============================] - 1s 98ms/step - loss: 3.0581 - accuracy: 0.1905 - val_loss: 4.9533 - val_accuracy: 0.1010\n",
      "Epoch 385/500\n",
      "9/9 [==============================] - 1s 120ms/step - loss: 3.0715 - accuracy: 0.1902 - val_loss: 4.9557 - val_accuracy: 0.1010\n",
      "Epoch 386/500\n",
      "9/9 [==============================] - 1s 93ms/step - loss: 3.0851 - accuracy: 0.1960 - val_loss: 4.9553 - val_accuracy: 0.1007\n",
      "Epoch 387/500\n",
      "9/9 [==============================] - 1s 110ms/step - loss: 3.0212 - accuracy: 0.1929 - val_loss: 4.9595 - val_accuracy: 0.0995\n",
      "Epoch 388/500\n",
      "9/9 [==============================] - 1s 93ms/step - loss: 3.0284 - accuracy: 0.1938 - val_loss: 4.9601 - val_accuracy: 0.0998\n",
      "Epoch 389/500\n",
      "9/9 [==============================] - 1s 113ms/step - loss: 3.0302 - accuracy: 0.1935 - val_loss: 4.9611 - val_accuracy: 0.0998\n",
      "Epoch 390/500\n",
      "9/9 [==============================] - 1s 89ms/step - loss: 3.0456 - accuracy: 0.1936 - val_loss: 4.9617 - val_accuracy: 0.1001\n",
      "Epoch 391/500\n",
      "9/9 [==============================] - 1s 101ms/step - loss: 3.0441 - accuracy: 0.1946 - val_loss: 4.9640 - val_accuracy: 0.0995\n",
      "Epoch 392/500\n",
      "9/9 [==============================] - 1s 131ms/step - loss: 3.0303 - accuracy: 0.1917 - val_loss: 4.9655 - val_accuracy: 0.1007\n",
      "Epoch 393/500\n",
      "9/9 [==============================] - 1s 109ms/step - loss: 3.0350 - accuracy: 0.1927 - val_loss: 4.9662 - val_accuracy: 0.0987\n",
      "Epoch 394/500\n",
      "9/9 [==============================] - 1s 94ms/step - loss: 3.0117 - accuracy: 0.1936 - val_loss: 4.9666 - val_accuracy: 0.1001\n",
      "Epoch 395/500\n",
      "9/9 [==============================] - 1s 103ms/step - loss: 3.0022 - accuracy: 0.1962 - val_loss: 4.9672 - val_accuracy: 0.0995\n",
      "Epoch 396/500\n",
      "9/9 [==============================] - 1s 100ms/step - loss: 3.0108 - accuracy: 0.1929 - val_loss: 4.9676 - val_accuracy: 0.0992\n",
      "Epoch 397/500\n",
      "9/9 [==============================] - 1s 97ms/step - loss: 2.9777 - accuracy: 0.1980 - val_loss: 4.9682 - val_accuracy: 0.0992\n",
      "Epoch 398/500\n",
      "9/9 [==============================] - 1s 119ms/step - loss: 3.0187 - accuracy: 0.1962 - val_loss: 4.9696 - val_accuracy: 0.0981\n",
      "Epoch 399/500\n",
      "9/9 [==============================] - 1s 94ms/step - loss: 2.9858 - accuracy: 0.1939 - val_loss: 4.9706 - val_accuracy: 0.0978\n",
      "Epoch 400/500\n",
      "9/9 [==============================] - 1s 126ms/step - loss: 2.9957 - accuracy: 0.1970 - val_loss: 4.9711 - val_accuracy: 0.0992\n",
      "Epoch 401/500\n",
      "9/9 [==============================] - 1s 100ms/step - loss: 2.9457 - accuracy: 0.1941 - val_loss: 4.9736 - val_accuracy: 0.0978\n",
      "Epoch 402/500\n",
      "9/9 [==============================] - 1s 110ms/step - loss: 2.9657 - accuracy: 0.1992 - val_loss: 4.9749 - val_accuracy: 0.0978\n",
      "Epoch 403/500\n",
      "9/9 [==============================] - 1s 85ms/step - loss: 2.9688 - accuracy: 0.2014 - val_loss: 4.9765 - val_accuracy: 0.0984\n",
      "Epoch 404/500\n",
      "9/9 [==============================] - 1s 104ms/step - loss: 2.9628 - accuracy: 0.1977 - val_loss: 4.9772 - val_accuracy: 0.0987\n",
      "Epoch 405/500\n",
      "9/9 [==============================] - 1s 95ms/step - loss: 2.9307 - accuracy: 0.1996 - val_loss: 4.9794 - val_accuracy: 0.0981\n",
      "Epoch 406/500\n",
      "9/9 [==============================] - 1s 111ms/step - loss: 2.9545 - accuracy: 0.2007 - val_loss: 4.9795 - val_accuracy: 0.0981\n",
      "Epoch 407/500\n",
      "9/9 [==============================] - 1s 99ms/step - loss: 2.9319 - accuracy: 0.2001 - val_loss: 4.9805 - val_accuracy: 0.0984\n",
      "Epoch 408/500\n",
      "9/9 [==============================] - 1s 96ms/step - loss: 2.9411 - accuracy: 0.2022 - val_loss: 4.9812 - val_accuracy: 0.0978\n",
      "Epoch 409/500\n",
      "9/9 [==============================] - 1s 104ms/step - loss: 2.9338 - accuracy: 0.2045 - val_loss: 4.9815 - val_accuracy: 0.0978\n",
      "Epoch 410/500\n",
      "9/9 [==============================] - 1s 92ms/step - loss: 2.9640 - accuracy: 0.2008 - val_loss: 4.9820 - val_accuracy: 0.0981\n",
      "Epoch 411/500\n",
      "9/9 [==============================] - 1s 110ms/step - loss: 2.8921 - accuracy: 0.2024 - val_loss: 4.9826 - val_accuracy: 0.0975\n",
      "Epoch 412/500\n",
      "9/9 [==============================] - 1s 88ms/step - loss: 2.9307 - accuracy: 0.2065 - val_loss: 4.9832 - val_accuracy: 0.0969\n",
      "Epoch 413/500\n",
      "9/9 [==============================] - 1s 105ms/step - loss: 2.9095 - accuracy: 0.2030 - val_loss: 4.9846 - val_accuracy: 0.0972\n",
      "Epoch 414/500\n",
      "9/9 [==============================] - 1s 96ms/step - loss: 2.9396 - accuracy: 0.2000 - val_loss: 4.9861 - val_accuracy: 0.0961\n",
      "Epoch 415/500\n",
      "9/9 [==============================] - 1s 100ms/step - loss: 2.9488 - accuracy: 0.2059 - val_loss: 4.9865 - val_accuracy: 0.0966\n",
      "Epoch 416/500\n",
      "9/9 [==============================] - 1s 121ms/step - loss: 2.9060 - accuracy: 0.2047 - val_loss: 4.9885 - val_accuracy: 0.0969\n",
      "Epoch 417/500\n",
      "9/9 [==============================] - 1s 103ms/step - loss: 2.9074 - accuracy: 0.2038 - val_loss: 4.9889 - val_accuracy: 0.0966\n",
      "Epoch 418/500\n",
      "9/9 [==============================] - 1s 103ms/step - loss: 2.8886 - accuracy: 0.2023 - val_loss: 4.9904 - val_accuracy: 0.0964\n",
      "Epoch 419/500\n",
      "9/9 [==============================] - 1s 96ms/step - loss: 2.8523 - accuracy: 0.2047 - val_loss: 4.9915 - val_accuracy: 0.0964\n",
      "Epoch 420/500\n",
      "9/9 [==============================] - 1s 110ms/step - loss: 2.9053 - accuracy: 0.2048 - val_loss: 4.9926 - val_accuracy: 0.0964\n",
      "Epoch 421/500\n",
      "9/9 [==============================] - 1s 102ms/step - loss: 2.8571 - accuracy: 0.2090 - val_loss: 4.9948 - val_accuracy: 0.0958\n",
      "Epoch 422/500\n",
      "9/9 [==============================] - 1s 115ms/step - loss: 2.8836 - accuracy: 0.2043 - val_loss: 4.9953 - val_accuracy: 0.0964\n",
      "Epoch 423/500\n",
      "9/9 [==============================] - 1s 90ms/step - loss: 2.8900 - accuracy: 0.2089 - val_loss: 4.9967 - val_accuracy: 0.0969\n",
      "Epoch 424/500\n",
      "9/9 [==============================] - 1s 113ms/step - loss: 2.8649 - accuracy: 0.2058 - val_loss: 4.9985 - val_accuracy: 0.0972\n",
      "Epoch 425/500\n",
      "9/9 [==============================] - 1s 102ms/step - loss: 2.8887 - accuracy: 0.2070 - val_loss: 4.9993 - val_accuracy: 0.0964\n",
      "Epoch 426/500\n",
      "9/9 [==============================] - 1s 102ms/step - loss: 2.8703 - accuracy: 0.2073 - val_loss: 5.0014 - val_accuracy: 0.0966\n",
      "Epoch 427/500\n",
      "9/9 [==============================] - 1s 95ms/step - loss: 2.8605 - accuracy: 0.2050 - val_loss: 5.0021 - val_accuracy: 0.0969\n",
      "Epoch 428/500\n",
      "9/9 [==============================] - 1s 103ms/step - loss: 2.8769 - accuracy: 0.2072 - val_loss: 5.0045 - val_accuracy: 0.0969\n",
      "Epoch 429/500\n",
      "9/9 [==============================] - 1s 106ms/step - loss: 2.8406 - accuracy: 0.2103 - val_loss: 5.0048 - val_accuracy: 0.0978\n",
      "Epoch 430/500\n",
      "9/9 [==============================] - 1s 93ms/step - loss: 2.8300 - accuracy: 0.2072 - val_loss: 5.0070 - val_accuracy: 0.0969\n",
      "Epoch 431/500\n",
      "9/9 [==============================] - 1s 94ms/step - loss: 2.8343 - accuracy: 0.2092 - val_loss: 5.0074 - val_accuracy: 0.0978\n",
      "Epoch 432/500\n",
      "9/9 [==============================] - 1s 112ms/step - loss: 2.8681 - accuracy: 0.2089 - val_loss: 5.0100 - val_accuracy: 0.0972\n",
      "Epoch 433/500\n",
      "9/9 [==============================] - 1s 91ms/step - loss: 2.8243 - accuracy: 0.2088 - val_loss: 5.0103 - val_accuracy: 0.0975\n",
      "Epoch 434/500\n",
      "9/9 [==============================] - 1s 109ms/step - loss: 2.8701 - accuracy: 0.2130 - val_loss: 5.0131 - val_accuracy: 0.0969\n",
      "Epoch 435/500\n",
      "9/9 [==============================] - 1s 104ms/step - loss: 2.8320 - accuracy: 0.2136 - val_loss: 5.0138 - val_accuracy: 0.0978\n",
      "Epoch 436/500\n",
      "9/9 [==============================] - 1s 112ms/step - loss: 2.8532 - accuracy: 0.2059 - val_loss: 5.0160 - val_accuracy: 0.0972\n",
      "Epoch 437/500\n",
      "9/9 [==============================] - 1s 96ms/step - loss: 2.8487 - accuracy: 0.2123 - val_loss: 5.0166 - val_accuracy: 0.0975\n",
      "Epoch 438/500\n",
      "9/9 [==============================] - 1s 101ms/step - loss: 2.8013 - accuracy: 0.2117 - val_loss: 5.0188 - val_accuracy: 0.0975\n",
      "Epoch 439/500\n",
      "9/9 [==============================] - 1s 106ms/step - loss: 2.8340 - accuracy: 0.2119 - val_loss: 5.0210 - val_accuracy: 0.0975\n",
      "Epoch 440/500\n",
      "9/9 [==============================] - 1s 91ms/step - loss: 2.8041 - accuracy: 0.2089 - val_loss: 5.0225 - val_accuracy: 0.0972\n",
      "Epoch 441/500\n",
      "9/9 [==============================] - 1s 94ms/step - loss: 2.8054 - accuracy: 0.2152 - val_loss: 5.0242 - val_accuracy: 0.0975\n",
      "Epoch 442/500\n",
      "9/9 [==============================] - 1s 115ms/step - loss: 2.7857 - accuracy: 0.2148 - val_loss: 5.0261 - val_accuracy: 0.0972\n",
      "Epoch 443/500\n",
      "9/9 [==============================] - 1s 87ms/step - loss: 2.7863 - accuracy: 0.2140 - val_loss: 5.0271 - val_accuracy: 0.0975\n",
      "Epoch 444/500\n",
      "9/9 [==============================] - 1s 108ms/step - loss: 2.8049 - accuracy: 0.2091 - val_loss: 5.0284 - val_accuracy: 0.0981\n",
      "Epoch 445/500\n",
      "9/9 [==============================] - 1s 95ms/step - loss: 2.8080 - accuracy: 0.2143 - val_loss: 5.0301 - val_accuracy: 0.0981\n",
      "Epoch 446/500\n",
      "9/9 [==============================] - 1s 101ms/step - loss: 2.7901 - accuracy: 0.2129 - val_loss: 5.0314 - val_accuracy: 0.0984\n",
      "Epoch 447/500\n",
      "9/9 [==============================] - 1s 106ms/step - loss: 2.7793 - accuracy: 0.2131 - val_loss: 5.0345 - val_accuracy: 0.0984\n",
      "Epoch 448/500\n",
      "9/9 [==============================] - 1s 94ms/step - loss: 2.7666 - accuracy: 0.2129 - val_loss: 5.0360 - val_accuracy: 0.0978\n",
      "Epoch 449/500\n",
      "9/9 [==============================] - 1s 109ms/step - loss: 2.7779 - accuracy: 0.2141 - val_loss: 5.0372 - val_accuracy: 0.0984\n",
      "Epoch 450/500\n",
      "9/9 [==============================] - 1s 111ms/step - loss: 2.8008 - accuracy: 0.2122 - val_loss: 5.0386 - val_accuracy: 0.0987\n",
      "Epoch 451/500\n",
      "9/9 [==============================] - 1s 95ms/step - loss: 2.7708 - accuracy: 0.2138 - val_loss: 5.0403 - val_accuracy: 0.0990\n",
      "Epoch 452/500\n",
      "9/9 [==============================] - 1s 91ms/step - loss: 2.7938 - accuracy: 0.2146 - val_loss: 5.0426 - val_accuracy: 0.0987\n",
      "Epoch 453/500\n",
      "9/9 [==============================] - 1s 105ms/step - loss: 2.7783 - accuracy: 0.2163 - val_loss: 5.0432 - val_accuracy: 0.0987\n",
      "Epoch 454/500\n",
      "9/9 [==============================] - 1s 93ms/step - loss: 2.7954 - accuracy: 0.2181 - val_loss: 5.0468 - val_accuracy: 0.0981\n",
      "Epoch 455/500\n",
      "9/9 [==============================] - 1s 92ms/step - loss: 2.8030 - accuracy: 0.2191 - val_loss: 5.0470 - val_accuracy: 0.0984\n",
      "Epoch 456/500\n",
      "9/9 [==============================] - 1s 96ms/step - loss: 2.7786 - accuracy: 0.2102 - val_loss: 5.0494 - val_accuracy: 0.0984\n",
      "Epoch 457/500\n",
      "9/9 [==============================] - 1s 116ms/step - loss: 2.7590 - accuracy: 0.2174 - val_loss: 5.0503 - val_accuracy: 0.0987\n",
      "Epoch 458/500\n",
      "9/9 [==============================] - 1s 108ms/step - loss: 2.7672 - accuracy: 0.2146 - val_loss: 5.0529 - val_accuracy: 0.0990\n",
      "Epoch 459/500\n",
      "9/9 [==============================] - 1s 121ms/step - loss: 2.7367 - accuracy: 0.2160 - val_loss: 5.0537 - val_accuracy: 0.0987\n",
      "Epoch 460/500\n",
      "9/9 [==============================] - 1s 90ms/step - loss: 2.8062 - accuracy: 0.2174 - val_loss: 5.0561 - val_accuracy: 0.0987\n",
      "Epoch 461/500\n",
      "9/9 [==============================] - 1s 117ms/step - loss: 2.7395 - accuracy: 0.2189 - val_loss: 5.0579 - val_accuracy: 0.0990\n",
      "Epoch 462/500\n",
      "9/9 [==============================] - 1s 88ms/step - loss: 2.7610 - accuracy: 0.2173 - val_loss: 5.0594 - val_accuracy: 0.0992\n",
      "Epoch 463/500\n",
      "9/9 [==============================] - 1s 109ms/step - loss: 2.7425 - accuracy: 0.2187 - val_loss: 5.0615 - val_accuracy: 0.0990\n",
      "Epoch 464/500\n",
      "9/9 [==============================] - 1s 97ms/step - loss: 2.7417 - accuracy: 0.2212 - val_loss: 5.0630 - val_accuracy: 0.0992\n",
      "Epoch 465/500\n",
      "9/9 [==============================] - 1s 105ms/step - loss: 2.7342 - accuracy: 0.2162 - val_loss: 5.0652 - val_accuracy: 0.0990\n",
      "Epoch 466/500\n",
      "9/9 [==============================] - 1s 101ms/step - loss: 2.7400 - accuracy: 0.2206 - val_loss: 5.0660 - val_accuracy: 0.0992\n",
      "Epoch 467/500\n",
      "9/9 [==============================] - 1s 94ms/step - loss: 2.7549 - accuracy: 0.2205 - val_loss: 5.0681 - val_accuracy: 0.0987\n",
      "Epoch 468/500\n",
      "9/9 [==============================] - 1s 103ms/step - loss: 2.7167 - accuracy: 0.2161 - val_loss: 5.0707 - val_accuracy: 0.0990\n",
      "Epoch 469/500\n",
      "9/9 [==============================] - 1s 112ms/step - loss: 2.7449 - accuracy: 0.2206 - val_loss: 5.0717 - val_accuracy: 0.0992\n",
      "Epoch 470/500\n",
      "9/9 [==============================] - 1s 93ms/step - loss: 2.7427 - accuracy: 0.2165 - val_loss: 5.0734 - val_accuracy: 0.0992\n",
      "Epoch 471/500\n",
      "9/9 [==============================] - 1s 112ms/step - loss: 2.7485 - accuracy: 0.2185 - val_loss: 5.0745 - val_accuracy: 0.0995\n",
      "Epoch 472/500\n",
      "9/9 [==============================] - 1s 92ms/step - loss: 2.7162 - accuracy: 0.2277 - val_loss: 5.0777 - val_accuracy: 0.0992\n",
      "Epoch 473/500\n",
      "9/9 [==============================] - 1s 89ms/step - loss: 2.7645 - accuracy: 0.2188 - val_loss: 5.0791 - val_accuracy: 0.0992\n",
      "Epoch 474/500\n",
      "9/9 [==============================] - 1s 116ms/step - loss: 2.7392 - accuracy: 0.2206 - val_loss: 5.0814 - val_accuracy: 0.0992\n",
      "Epoch 475/500\n",
      "9/9 [==============================] - 1s 99ms/step - loss: 2.7268 - accuracy: 0.2197 - val_loss: 5.0821 - val_accuracy: 0.0992\n",
      "Epoch 476/500\n",
      "9/9 [==============================] - 1s 107ms/step - loss: 2.7181 - accuracy: 0.2234 - val_loss: 5.0863 - val_accuracy: 0.0990\n",
      "Epoch 477/500\n",
      "9/9 [==============================] - 1s 102ms/step - loss: 2.7207 - accuracy: 0.2207 - val_loss: 5.0857 - val_accuracy: 0.0998\n",
      "Epoch 478/500\n",
      "9/9 [==============================] - 1s 92ms/step - loss: 2.7364 - accuracy: 0.2204 - val_loss: 5.0905 - val_accuracy: 0.0992\n",
      "Epoch 479/500\n",
      "9/9 [==============================] - 1s 113ms/step - loss: 2.7013 - accuracy: 0.2207 - val_loss: 5.0907 - val_accuracy: 0.0992\n",
      "Epoch 480/500\n",
      "9/9 [==============================] - 1s 89ms/step - loss: 2.7307 - accuracy: 0.2256 - val_loss: 5.0943 - val_accuracy: 0.0987\n",
      "Epoch 481/500\n",
      "9/9 [==============================] - 1s 114ms/step - loss: 2.7126 - accuracy: 0.2219 - val_loss: 5.0952 - val_accuracy: 0.0992\n",
      "Epoch 482/500\n",
      "9/9 [==============================] - 1s 99ms/step - loss: 2.7057 - accuracy: 0.2224 - val_loss: 5.0987 - val_accuracy: 0.0995\n",
      "Epoch 483/500\n",
      "9/9 [==============================] - 1s 117ms/step - loss: 2.6802 - accuracy: 0.2284 - val_loss: 5.0991 - val_accuracy: 0.0995\n",
      "Epoch 484/500\n",
      "9/9 [==============================] - 1s 89ms/step - loss: 2.6891 - accuracy: 0.2218 - val_loss: 5.1025 - val_accuracy: 0.0990\n",
      "Epoch 485/500\n",
      "9/9 [==============================] - 1s 92ms/step - loss: 2.6981 - accuracy: 0.2217 - val_loss: 5.1035 - val_accuracy: 0.0992\n",
      "Epoch 486/500\n",
      "9/9 [==============================] - 1s 95ms/step - loss: 2.7024 - accuracy: 0.2233 - val_loss: 5.1056 - val_accuracy: 0.0990\n",
      "Epoch 487/500\n",
      "9/9 [==============================] - 1s 103ms/step - loss: 2.6948 - accuracy: 0.2252 - val_loss: 5.1091 - val_accuracy: 0.0998\n",
      "Epoch 488/500\n",
      "9/9 [==============================] - 1s 102ms/step - loss: 2.6847 - accuracy: 0.2253 - val_loss: 5.1105 - val_accuracy: 0.0998\n",
      "Epoch 489/500\n",
      "9/9 [==============================] - 1s 92ms/step - loss: 2.6754 - accuracy: 0.2220 - val_loss: 5.1127 - val_accuracy: 0.0998\n",
      "Epoch 490/500\n",
      "9/9 [==============================] - 1s 107ms/step - loss: 2.7086 - accuracy: 0.2245 - val_loss: 5.1133 - val_accuracy: 0.0998\n",
      "Epoch 491/500\n",
      "9/9 [==============================] - 1s 89ms/step - loss: 2.7035 - accuracy: 0.2239 - val_loss: 5.1165 - val_accuracy: 0.0992\n",
      "Epoch 492/500\n",
      "9/9 [==============================] - 1s 121ms/step - loss: 2.6725 - accuracy: 0.2244 - val_loss: 5.1193 - val_accuracy: 0.0995\n",
      "Epoch 493/500\n",
      "9/9 [==============================] - 1s 87ms/step - loss: 2.6459 - accuracy: 0.2293 - val_loss: 5.1224 - val_accuracy: 0.1004\n",
      "Epoch 494/500\n",
      "9/9 [==============================] - 1s 97ms/step - loss: 2.6633 - accuracy: 0.2244 - val_loss: 5.1218 - val_accuracy: 0.1004\n",
      "Epoch 495/500\n",
      "9/9 [==============================] - 1s 104ms/step - loss: 2.6715 - accuracy: 0.2252 - val_loss: 5.1252 - val_accuracy: 0.1004\n",
      "Epoch 496/500\n",
      "9/9 [==============================] - 1s 95ms/step - loss: 2.6685 - accuracy: 0.2227 - val_loss: 5.1256 - val_accuracy: 0.0998\n",
      "Epoch 497/500\n",
      "9/9 [==============================] - 1s 108ms/step - loss: 2.7004 - accuracy: 0.2240 - val_loss: 5.1288 - val_accuracy: 0.0998\n",
      "Epoch 498/500\n",
      "9/9 [==============================] - 1s 91ms/step - loss: 2.6140 - accuracy: 0.2255 - val_loss: 5.1315 - val_accuracy: 0.1007\n",
      "Epoch 499/500\n",
      "9/9 [==============================] - 1s 93ms/step - loss: 2.6779 - accuracy: 0.2245 - val_loss: 5.1340 - val_accuracy: 0.1004\n",
      "Epoch 500/500\n",
      "9/9 [==============================] - 1s 114ms/step - loss: 2.6491 - accuracy: 0.2240 - val_loss: 5.1354 - val_accuracy: 0.0998\n"
     ]
    }
   ],
   "source": [
    "r = model.fit(\n",
    "    [input_sequences, z, z],\n",
    "    one_hot_targets,\n",
    "    epochs=EPOCHS,\n",
    "    validation_split=VALIDATION_SPLIT,\n",
    "    batch_size=BATCH_SIZE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "input2 = Input(shape=(1,))\n",
    "x = embedding_layer(input2)\n",
    "x, h, c = lstm(x, initial_state=[initial_h, initial_c])\n",
    "output2 = dense(x)\n",
    "sampling_model = Model([input2, initial_h, initial_c], [output2, h, c])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx2word = {v:k for k,v in word2idx.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_line():\n",
    "    # initial inputs\n",
    "    np_input = np.array([[word2idx['<sos>']]])\n",
    "    h = np.zeros((1, LATENT_DIM))\n",
    "    c = np.zeros((1, LATENT_DIM))\n",
    "    print(f'np_input: {np_input}')\n",
    "\n",
    "    # so we know when to quit\n",
    "    eos = word2idx['<eos>']\n",
    "\n",
    "    # store the output here\n",
    "    output_sentence = []\n",
    "\n",
    "    for _ in range(max_sequence_length):\n",
    "        o, h, c = sampling_model.predict([np_input, h, c])\n",
    "\n",
    "        print(\"o:\", o.shape)\n",
    "        # idx = np.argmax(o[0,0])\n",
    "        probs = o[0, 0]\n",
    "        if np.argmax(probs) == 0:\n",
    "            print(\"wtf\")\n",
    "        probs[0] = 0\n",
    "        probs /= probs.sum()\n",
    "        idx = np.random.choice(len(probs), p=probs)\n",
    "        if idx == eos:\n",
    "            break\n",
    "\n",
    "        # accuulate output\n",
    "        output_sentence.append(idx2word.get(idx, '<WTF %s>' % idx))\n",
    "\n",
    "        # make the next input into model\n",
    "        np_input[0, 0] = idx\n",
    "\n",
    "    return ' '.join(output_sentence)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "np_input: [[1]]\n",
      "o: (1, 1, 3057)\n",
      "o: (1, 1, 3057)\n",
      "o: (1, 1, 3057)\n",
      "o: (1, 1, 3057)\n",
      "o: (1, 1, 3057)\n",
      "o: (1, 1, 3057)\n",
      "o: (1, 1, 3057)\n",
      "o: (1, 1, 3057)\n",
      "o: (1, 1, 3057)\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'that seize rushes to go dig buried light'"
      ]
     },
     "metadata": {},
     "execution_count": 49
    }
   ],
   "source": [
    "sample_line()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "while True:\n",
    "    for _ in range(4):\n",
    "        print(sample_line())\n",
    "\n",
    "    ans = input(\"---generate another? [Y/n]---\")\n",
    "    if ans and ans[0].lower().startswith('n'):\n",
    "        break\n"
   ]
  }
 ]
}